## 逻辑回归模型
逻辑回归是一种分类模型，根据输入$x\in R^n$，来判断输出Y的类别（Y=1，正类；Y=0，负类），参数为权值$w\in R^n$和偏置$b\in R$。

逻辑回归把输出作为随机变量Y对于输入X的条件概率，取值范围限定在[0,1]，一般情况下，若大于0.5则Y=1，否则Y=0。从广义的线性模型角度考虑，$w\cdot x +b$ 是线性回归的输出，但它的取值范围是全体实数，
逻辑回归为了把输出的范围限定在[0,1]，引入logistic函数：
$$ g(x) = \frac {1}{1+e^{-x}} $$
logistic函数单调且可微，x趋向正无穷时，g(x)趋向1；x趋向负无穷时，g(x)趋向0；x=0时，g(x)=0.5。



Y对于X的条件概率分布如下：

$$P(Y=1|X) = \frac {1}{1+e^{-(w\cdot x +b)}}$$
$$P(Y=0|X) = \frac {e^{-(w\cdot x +b)}}{1+e^{-(w\cdot x +b)}}$$

logistic函数又称为对数几率函数。几率（odds）定义为：事件发生概率和不发生概率之间的比值，即$odds = \frac p {1-p}$。据此，可以计算得到：
$$ln\frac {P(Y=1|X)}{1 - P(Y=0|X)} = w\cdot x +b$$

换句话说，逻辑回归就是将线性回归的输出$w\cdot x +b$来拟合对数几率函数（logistic函数），核心就是将线性回归输出的取值范围从全体实数映射到概率取值[0,1]之间。

## 最大似然估计参数
逻辑回归模型学习时，给定数据集$(x_1,y_1),(x_2,y_2), ... ,(x_n,y_n)$，用最大似然法来估计参数。

单个样本的概率 $p_i = P(Y=1|X)^{y_i}P(Y=0|X)^{1-y_i}$，所以似然函数为：
$$\prod_{i=1}^n P(Y=1|X)^{y_i}P(Y=0|X)^{1-y_i}$$
设logistic函数为g(x), 对数似然函数为：
$$\sum_{i=1}^n [y_i log(g(x)) + (1-y_i)log(1-g(x))]$$ 

要最大化对数似然函数，即最小化：
$$- \frac 1n \sum_{i=1}^n [y_i log(g(x)) + (1-y_i)log(1-g(x))]$$

上式即交叉熵（Cross-Entropy）损失函数，通过梯度下降等方法可以解这个最优化问题，得到逻辑回归的参数w,b。